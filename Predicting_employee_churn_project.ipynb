{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project description\r\n",
    "\r\n",
    "## Dataset\r\n",
    "The dataset has 15000 records and 10 variables.\r\n",
    "\r\n",
    "## Target\r\n",
    "The dataset has a variable churn. In this excercise, we define 1 as employees who left the company and 0 as employees who stayed.\r\n",
    "The objective is to create a model that classify left/stayed employees.\r\n",
    "\r\n",
    "## Process\r\n",
    "- Analyzing and transforming categorical variables\r\n",
    "- Fitting a decision tree\r\n",
    "- Understanding overfitting\r\n",
    "- Analyzing acuraccy metrics: precision, recall, AUC/ROC\r\n",
    "- Hyperparameter tunning\r\n",
    "- Importance features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "#!pip install matplotlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# import libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "# split datatset for validation\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "# metrics\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "# models\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "# graphical tools\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.tree import export_graphviz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# read the data file\r\n",
    "data = pd.read_csv(\"./turnover.csv\")\r\n",
    "# check data info\r\n",
    "data.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   satisfaction          14999 non-null  float64\n",
      " 1   evaluation            14999 non-null  float64\n",
      " 2   number_of_projects    14999 non-null  int64  \n",
      " 3   average_montly_hours  14999 non-null  int64  \n",
      " 4   time_spend_company    14999 non-null  int64  \n",
      " 5   work_accident         14999 non-null  int64  \n",
      " 6   churn                 14999 non-null  int64  \n",
      " 7   promotion             14999 non-null  int64  \n",
      " 8   department            14999 non-null  object \n",
      " 9   salary                14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a few variables (objects) in our dataset: salary and department.\r\n",
    "\r\n",
    "## Analyzing the dataset\r\n",
    "\r\n",
    "Let's check these two and transform to numerical to make them more suitable for modeling."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Print the unique values of the \"department\" column\r\n",
    "print(data.department.unique())\r\n",
    "\r\n",
    "# Print the unique values of the \"salary\" column\r\n",
    "print(data.salary.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Encoding categories**\r\n",
    "\r\n",
    "The model will need some help to understand that it's dealing with categories. We will encode categories of the salary variable, which you know is ordinal based on the values observed before.\r\n",
    "This means that each level will be encoded with a number according of ordering: 0 to low, 1 to medium, and 2 to high."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "## SALARY variable\r\n",
    "# Change the type of the \"salary\" column to categorical\r\n",
    "data.salary = data.salary.astype('category')\r\n",
    "\r\n",
    "# Provide the correct order of categories\r\n",
    "data.salary = data.salary.cat.reorder_categories(['low', 'medium', 'high'])\r\n",
    "\r\n",
    "# Encode categories\r\n",
    "data.salary = data.salary.cat.codes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "## DEPARTMENT variable\r\n",
    "# Get dummies and save them inside a new DataFrame\r\n",
    "departments = pd.get_dummies(data.department)\r\n",
    "\r\n",
    "# Take a quick look to the first 5 rows of the new DataFrame called departments\r\n",
    "departments.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>accounting</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  RandD  accounting  hr  management  marketing  product_mng  sales  \\\n",
       "0   0      0           0   0           0          0            0      1   \n",
       "1   0      0           0   0           0          0            0      1   \n",
       "2   0      0           0   0           0          0            0      1   \n",
       "3   0      0           0   0           0          0            0      1   \n",
       "4   0      0           0   0           0          0            0      1   \n",
       "\n",
       "   support  technical  \n",
       "0        0          0  \n",
       "1        0          0  \n",
       "2        0          0  \n",
       "3        0          0  \n",
       "4        0          0  "
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Drop the \"accounting\" column to avoid \"dummy trap\"\r\n",
    "departments = departments.drop(\"accounting\", axis=1)\r\n",
    "\r\n",
    "# Drop the old column \"department\" as you don't need it anymore\r\n",
    "data = data.drop(\"department\", axis=1)\r\n",
    "\r\n",
    "# Join the new dataframe \"departments\" to your employee dataset: done\r\n",
    "data = data.join(departments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Check the new dataset\r\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>number_of_projects</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>churn</th>\n",
       "      <th>promotion</th>\n",
       "      <th>salary</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction  evaluation  number_of_projects  average_montly_hours  \\\n",
       "0          0.38        0.53                   2                   157   \n",
       "1          0.80        0.86                   5                   262   \n",
       "2          0.11        0.88                   7                   272   \n",
       "3          0.72        0.87                   5                   223   \n",
       "4          0.37        0.52                   2                   159   \n",
       "\n",
       "   time_spend_company  work_accident  churn  promotion  salary  IT  RandD  hr  \\\n",
       "0                   3              0      1          0       0   0      0   0   \n",
       "1                   6              0      1          0       1   0      0   0   \n",
       "2                   4              0      1          0       1   0      0   0   \n",
       "3                   5              0      1          0       0   0      0   0   \n",
       "4                   3              0      1          0       0   0      0   0   \n",
       "\n",
       "   management  marketing  product_mng  sales  support  technical  \n",
       "0           0          0            0      1        0          0  \n",
       "1           0          0            0      1        0          0  \n",
       "2           0          0            0      1        0          0  \n",
       "3           0          0            0      1        0          0  \n",
       "4           0          0            0      1        0          0  "
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Percentage of employees who churn**\r\n",
    "\r\n",
    "The column churn is providing information about whether an employee has left the company or not:\r\n",
    "- if the value of this column is 0, the employee is still with the company\r\n",
    "- if the value of this column is 1, then the employee has left the company\r\n",
    "\r\n",
    "Let’s calculate the turnover rate:\r\n",
    "- first count the number of times the variable churn has the value 1 and the value 0, respectively\r\n",
    "- then divide both counts by the total, and multiply the result by 100 to get the percentage of employees who left and stayed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Use len() function to get the total number of observations and save it as the number of employees\r\n",
    "n_employees = len(data)\r\n",
    "\r\n",
    "# Print the number of employees who left/stayed\r\n",
    "print(data.churn.value_counts())\r\n",
    "\r\n",
    "# Print the percentage of employees who left/stayed\r\n",
    "print(data.churn.value_counts()/n_employees*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    11428\n",
      "1     3571\n",
      "Name: churn, dtype: int64\n",
      "0    76.191746\n",
      "1    23.808254\n",
      "Name: churn, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Separating Target and Features**\r\n",
    "\r\n",
    "In order to make a prediction (in this case, whether an employee would leave or not), one needs to separate the dataset into two components:\r\n",
    "\r\n",
    "- the dependent variable or target which needs to be predicted\r\n",
    "- the independent variables or features that will be used to make a prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Set the target and features\r\n",
    "\r\n",
    "# Choose the dependent variable column (churn) and set it as target\r\n",
    "target = data.churn\r\n",
    "\r\n",
    "# Drop column churn and set everything else as features\r\n",
    "features = data.drop(\"churn\",axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Create the splits both for target and for features\r\n",
    "# Set the test sample to be 25% of your observations\r\n",
    "target_train, target_test, features_train, features_test = train_test_split(target,features,test_size=0.25,random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Initialize it and call model by specifying the random_state parameter\r\n",
    "model = DecisionTreeClassifier(random_state=42)\r\n",
    "\r\n",
    "# Apply a decision tree model to fit features to the target\r\n",
    "model.fit(features_train, target_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Apply a decision tree model to fit features to the target in the training set\r\n",
    "model.fit(features_train,target_train)\r\n",
    "\r\n",
    "# Check the accuracy score of the prediction for the training set\r\n",
    "print('training accuracy: ', model.score(features_train,target_train)*100)\r\n",
    "\r\n",
    "# Check the accuracy score of the prediction for the test set\r\n",
    "print('test accuracy: ', model.score(features_test,target_test)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training accuracy:  100.0\n",
      "test accuracy:  97.22666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This looks like the model is overfitted and it migh fail with unseen data. This is beacuse the tree has grown in deep and min leaves in each node that there are so many rules to classify target."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Export the tree to a dot file and preview it in webgraphviz.com\r\n",
    "export_graphviz(model,\"tree.dot\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pruning the tree\r\n",
    "Overfitting is a classic problem in analytics, especially for the decision tree algorithm. Once the tree is fully grown, it may provide highly accurate predictions for the training sample, yet fail to be that accurate on the test set. For that reason, the growth of the decision tree is usually controlled by:\r\n",
    "\r\n",
    "- “Pruning” the tree and setting a limit on the maximum depth it can have.\r\n",
    "- Limiting the minimum number of observations in one leaf of the tree."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Initialize the DecisionTreeClassifier while limiting the depth of the tree to 5\r\n",
    "model_depth_5 = DecisionTreeClassifier(max_depth=5, random_state=42)\r\n",
    "\r\n",
    "# Fit the model\r\n",
    "model_depth_5.fit(features_train,target_train)\r\n",
    "\r\n",
    "# Print the accuracy of the prediction for the training set\r\n",
    "print('training accuracy: ', model_depth_5.score(features_train,target_train)*100)\r\n",
    "\r\n",
    "# Print the accuracy of the prediction for the test set\r\n",
    "print('test accuracy: ', model_depth_5.score(features_test,target_test)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training accuracy:  97.71535247577563\n",
      "test accuracy:  97.06666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This looks like a more reasonable and realistic model. The gap between both accuracy is very little."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Limiting the sample size\r\n",
    "Another method to prevent overfitting is to specify the minimum number of observations necessary to grow a leaf (or node), in the Decision Tree."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Initialize the DecisionTreeClassifier while limiting the sample size in leaves to 100\r\n",
    "model_sample_100 = DecisionTreeClassifier(min_samples_leaf=100, random_state=42)\r\n",
    "\r\n",
    "# Fit the model\r\n",
    "model_sample_100.fit(features_train,target_train)\r\n",
    "\r\n",
    "# Print the accuracy of the prediction (in percentage points) for the training set\r\n",
    "print('training accuracy: ', model_sample_100.score(features_train,target_train)*100)\r\n",
    "\r\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\r\n",
    "print('test accuracy: ', model_sample_100.score(features_test,target_test)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training accuracy:  96.57747355320473\n",
      "test accuracy:  96.13333333333334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating accuracy metrics: precision\r\n",
    "The Precision score is an important metric used to measure the accuracy of a classification algorithm. It is calculated as the fraction of True Positives over the sum of True Positives and False Positives, or\r\n",
    " \r\n",
    "- we define True Positives as the number of employees who actually left, and were classified correctly as leaving\r\n",
    "- we define False Positives as the number of employees who actually stayed, but were wrongly classified as leaving\r\n",
    "- If there are no False Positives, the precision score is equal to 1. If there are no True Positives, the recall score is equal to 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Predict whether employees will churn using the test set\r\n",
    "prediction = model.predict(features_test)\r\n",
    "\r\n",
    "# Calculate precision score by comparing target_test with the prediction\r\n",
    "print('Precision: ', precision_score(target_test, prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision:  0.9240641711229947\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating accuracy metrics: recall\r\n",
    "The Recall score is another important metric used to measure the accuracy of a classification algorithm. It is calculated as the** fraction of True Positives over the sum of True Positives and False Negatives**\r\n",
    "\r\n",
    "If there are no False Negatives, the recall score is equal to 1. If there are no True Positives, the recall score is equal to 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Calculate recall score by comparing target_test with the prediction\r\n",
    "print('Recall: ', recall_score(target_test, prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall:  0.9632107023411371\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating the ROC/AUC score\r\n",
    "While the Recall score is an important metric for measuring the accuracy of a classification algorithm, it puts too much weight on the number of False Negatives. On the other hand, Precision is concentrated on the number of False Positives.\r\n",
    "\r\n",
    "The combination of those two results in the ROC curve allows us to measure both recall and precision. The area under the ROC curve is calculated as the AUC score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Calculate ROC/AUC score by comparing target_test with the prediction\r\n",
    "print('ROC: ', roc_auc_score(target_test, prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC:  0.9691623087590718\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Balancing classes\r\n",
    "It can significantly affect prediction results, as shown by the difference between the recall and accuracy scores. To solve the imbalance, equal weights are usually given to each class. Using the class_weight argument in sklearn's DecisionTreeClassifier, one can make the classes become \"balanced\".\r\n",
    "\r\n",
    "In this dataset, target variable is distributed:\r\n",
    "- class 0: 76% stayed\r\n",
    "- class 1: 24% left"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Initialize the DecisionTreeClassifier \r\n",
    "model_depth_5_b = DecisionTreeClassifier(max_depth=5,class_weight=\"balanced\",random_state=42)\r\n",
    "\r\n",
    "# Fit the model\r\n",
    "model_depth_5_b.fit(features_train,target_train)\r\n",
    "\r\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\r\n",
    "print('Accuracy with balanced classes: ', model_depth_5_b.score(features_test,target_test)*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy with balanced classes:  93.70666666666668\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are trading off some accuracy compared to the previous model with 97%. Let's compare models with unbalanced and balance weigths and the effect on precision (False positives)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Previous precision and AUC\r\n",
    "print('Unbalanced Precision: ', precision_score(target_test, prediction))\r\n",
    "print('Unbalanced AUC: ', roc_auc_score(target_test, prediction), '\\n')\r\n",
    "\r\n",
    "# Initialize the model\r\n",
    "model_depth_7_b = DecisionTreeClassifier(max_depth=7, class_weight='balanced', random_state=42)\r\n",
    "# Fit it to the training component\r\n",
    "model_depth_7_b.fit(features_train,target_train)\r\n",
    "# Make prediction using test component\r\n",
    "prediction_b = model_depth_7_b.predict(features_test)\r\n",
    "# Print the precision score for the balanced model\r\n",
    "print('Balanced Precision: ', precision_score(target_test, prediction_b))\r\n",
    "# Print the ROC/AUC score for the balanced model\r\n",
    "print('Balanced AUC: ', roc_auc_score(target_test, prediction_b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced Precision:  0.9240641711229947\n",
      "Unbalanced AUC:  0.9691623087590718 \n",
      "\n",
      "Balanced Precision:  0.9598163030998852\n",
      "Balanced AUC:  0.959863876199084\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross-validation using sklearn\r\n",
    "Overfitting the dataset is a common problem in analytics. This happens when a model has learned the data too closely: it has great performances on the dataset it was trained on, but fails to generalize outside of it.\r\n",
    "\r\n",
    "While the train/test split technique ensures that the model does not overfit the training set, hyperparameter tuning may result in overfitting the test component, since it consists in tuning the model to get the best prediction results on the test set. Therefore, it is recommended to validate the model on different testing sets. K-fold cross-validation allows us to achieve this:\r\n",
    "\r\n",
    "- it splits the dataset into a training set and a testing set\r\n",
    "- it fits the model, makes predictions and calculates a score (you can specify if you want the accuracy, precision, recall…)\r\n",
    "- it repeats the process k times in total\r\n",
    "- it outputs the average of the 10 scores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Use that function to print the cross validation score for 10 folds - unbalanced model\r\n",
    "print(cross_val_score(model,features,target,cv=10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.98533333 0.98533333 0.974      0.96533333 0.96       0.97933333\n",
      " 0.99       0.99333333 1.         1.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up GridSearch parameters\r\n",
    "A hyperparameter is a parameter inside a function. For example, max_depth or min_samples_leaf are hyperparameters of the DecisionTreeClassifier() function. Hyperparameter tuning is the process of testing different values of hyperparameters to find the optimal ones: the one that gives the best predictions according to your objectives. In sklearn, you can use GridSearch to test different combinations of hyperparameters. Even better, you can use GridSearchCV() test different combinations and run cross-validation on them in one function!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Generate values for maximum depth\r\n",
    "depth = [i for i in range(8,21,1)]\r\n",
    "\r\n",
    "# Generate values for minimum sample size\r\n",
    "samples = [i for i in range(80,300,20)]\r\n",
    "\r\n",
    "# Create the dictionary with parameters to be checked\r\n",
    "parameters = dict(max_depth=depth, min_samples_leaf=samples, class_weight=['balanced'])\r\n",
    "\r\n",
    "# initialize the param_search function using the GridSearchCV function, initial model and parameters above\r\n",
    "param_search = GridSearchCV(model, parameters)\r\n",
    "\r\n",
    "# fit the param_search to the training dataset\r\n",
    "param_search.fit(features_train, target_train)\r\n",
    "\r\n",
    "# print the best parameters found\r\n",
    "print(param_search.best_params_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'class_weight': 'balanced', 'max_depth': 8, 'min_samples_leaf': 120}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like the values that give you the best score are a minimum of samples per leaf of 120 and a maximum depth of 8."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "model_best = DecisionTreeClassifier(max_depth=8, min_samples_leaf=120, class_weight='balanced', random_state=42)\r\n",
    "model_best.fit(features_train, target_train)\r\n",
    "prediction_tunned = model_best.predict(features_test)\r\n",
    "# metrics\r\n",
    "print('Acuraccy CV: ', cross_val_score(model_best,features,target,cv=10).mean())\r\n",
    "print('Precision: ', precision_score(target_test, prediction_tunned))\r\n",
    "print('Recall: ', recall_score(target_test, prediction_tunned))\r\n",
    "print('AUC: ', roc_auc_score(target_test, prediction_tunned))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acuraccy CV:  0.9483285301311986\n",
      "Precision:  0.8865096359743041\n",
      "Recall:  0.9230769230769231\n",
      "AUC:  0.9429615249804524\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sorting important features\r\n",
    "Among other things, Decision Trees are very popular because of their interpretability. Many models can provide accurate predictions, but Decision Trees can also quantify the effect of the different features on the target. Here, it can tell you which features have the strongest and weakest impacts on the decision to leave the company. In sklearn, you can get this information by using the feature_importances_ attribute."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# Calculate feature importances\r\n",
    "feature_importances = model_best.feature_importances_\r\n",
    "\r\n",
    "# Create a list of features: done\r\n",
    "feature_list = list(features)\r\n",
    "\r\n",
    "# Save the results inside a DataFrame using feature_list as an index\r\n",
    "relative_importances = pd.DataFrame(index=feature_list, data=feature_importances, columns=[\"importance\"])\r\n",
    "\r\n",
    "# Sort values to learn most important features\r\n",
    "relative_importances.sort_values(by=\"importance\", ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction</th>\n",
       "      <td>0.503552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>0.382200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluation</th>\n",
       "      <td>0.086273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_projects</th>\n",
       "      <td>0.016207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>0.010423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical</th>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_accident</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_mng</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "satisfaction            0.503552\n",
       "time_spend_company      0.382200\n",
       "evaluation              0.086273\n",
       "number_of_projects      0.016207\n",
       "average_montly_hours    0.010423\n",
       "technical               0.000806\n",
       "salary                  0.000539\n",
       "promotion               0.000000\n",
       "work_accident           0.000000\n",
       "RandD                   0.000000\n",
       "hr                      0.000000\n",
       "management              0.000000\n",
       "marketing               0.000000\n",
       "product_mng             0.000000\n",
       "sales                   0.000000\n",
       "support                 0.000000\n",
       "IT                      0.000000"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that satisfaction is by far the most impactful feature on the decision to leave the company or not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Selecting importance features\r\n",
    "\r\n",
    "# select only features with relative importance higher than 1%\r\n",
    "selected_features = relative_importances[relative_importances.importance>0.01]\r\n",
    "\r\n",
    "# create a list from those features: done\r\n",
    "selected_list = selected_features.index\r\n",
    "\r\n",
    "# transform both features_train and features_test components to include only selected features\r\n",
    "features_train_selected = features_train[selected_list]\r\n",
    "features_test_selected = features_test[selected_list]\r\n",
    "\r\n",
    "# Print results\r\n",
    "print(list(features_train_selected))\r\n",
    "print(list(features_test_selected))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['satisfaction', 'evaluation', 'number_of_projects', 'average_montly_hours', 'time_spend_company']\n",
      "['satisfaction', 'evaluation', 'number_of_projects', 'average_montly_hours', 'time_spend_company']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! As you can see, only 5 features have been retained out of the 17 original ones: ['satisfaction', 'evaluation', 'number_of_projects', 'average_montly_hours', 'time_spend_company']. \r\n",
    "\r\n",
    "You’ve made sure to keep only these in your training and testing sets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Develop and test the best model with less variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Initialize the best model using parameters provided in description\r\n",
    "model_best = DecisionTreeClassifier(max_depth=8, min_samples_leaf=120, class_weight='balanced', random_state=42)\r\n",
    "\r\n",
    "# Fit the model using only selected features from training set: done\r\n",
    "model_best.fit(features_train_selected, target_train)\r\n",
    "\r\n",
    "# Make prediction based on selected list of features from test set\r\n",
    "prediction_best = model_best.predict(features_test_selected)\r\n",
    "\r\n",
    "# Print the general accuracy of the model_best\r\n",
    "print('Accuracy: ', model_best.score(features_test_selected, target_test) * 100)\r\n",
    "# Print the precision score of the model predictions\r\n",
    "print('Precision: ', precision_score(target_test, prediction_best) * 100)\r\n",
    "# Print the recall score of the model predictions\r\n",
    "print('Recall: ', recall_score(target_test, prediction_best) * 100)\r\n",
    "# Print the ROC/AUC score of the model predictions\r\n",
    "print('AUC: ', roc_auc_score(target_test, prediction_best) * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  95.33333333333334\n",
      "Precision:  88.6509635974304\n",
      "Recall:  92.3076923076923\n",
      "AUC:  94.29615249804525\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that identifying important features (only 5), the model is able to predict with high level of Recall employee churn without having too many false positives."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "0ce5b0d3d7016a78f38153d8febd9754ffd4cf578927e97417bc03228832e5f0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}